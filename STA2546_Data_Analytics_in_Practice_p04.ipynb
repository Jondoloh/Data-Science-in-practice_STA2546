{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jondoloh/Data-Science-in-practice_STA2546/blob/main/STA2546_Data_Analytics_in_Practice_p04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Libraries and Dependencies"
      ],
      "metadata": {
        "id": "fGAYHyy2LF_C"
      },
      "id": "fGAYHyy2LF_C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e76c148",
      "metadata": {
        "id": "6e76c148"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c4cc64",
      "metadata": {
        "id": "e1c4cc64"
      },
      "source": [
        "# 2) Preliminary Data Analysis\n",
        "\n",
        "####      a) Data extraction and train/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19665a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19665a0",
        "outputId": "40f537b2-fa59-4d68-a3c5-9fb7a35b7a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11314\n",
            "7532\n"
          ]
        }
      ],
      "source": [
        "# Import the fetch_20newsgroups function from sklearn's datasets module\n",
        "# The function retrieves the 20 newsgroups dataset\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "print(len(newsgroups_train.data))\n",
        "print(len(newsgroups_test.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91928998",
      "metadata": {
        "id": "91928998"
      },
      "source": [
        "#### b) Mapping to new categories"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code creates a new target label mapping from the original target labels in the \"newsgroups_train\" and \"newsgroups_test\" datasets\n",
        "# The original target labels are grouped into 6 categories and mapped to new target labels\n",
        "\n",
        "# Define the mapping from original target labels to new target labels\n",
        "target_names_new = [\"Religion\", \"Technology\", \"Other\", \"Recreation\", \"Science\", \"Politics\"]\n",
        "old_to_new_target = {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 2,\n",
        "                      7: 3, 8: 3, 9: 3, 10: 3, 11: 4, 12: 1, 13: 4,\n",
        "                      14: 4, 15: 0, 16: 5, 17: 5, 18: 5, 19: 5}\n",
        "\n",
        "# Create a list of new target labels for each example in the training and test sets\n",
        "new_target_list_train = [old_to_new_target[target] for target in newsgroups_train.target]\n",
        "new_target_list_test = [old_to_new_target[target] for target in newsgroups_test.target]\n",
        "\n",
        "# Add the new target labels and target label names as columns in the training and test sets\n",
        "newsgroups_train[\"new_target\"] = np.array(new_target_list_train)\n",
        "newsgroups_train[\"new_target_names\"] = np.array(target_names_new)\n",
        "newsgroups_test[\"new_target\"] = np.array(new_target_list_test)\n",
        "newsgroups_test[\"new_target_names\"] = np.array(target_names_new)"
      ],
      "metadata": {
        "id": "a1vAWJA6L6y9"
      },
      "id": "a1vAWJA6L6y9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e19b7ea",
      "metadata": {
        "id": "9e19b7ea"
      },
      "source": [
        "#### c) Vectorizing the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Tf-Idf vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Creating vectors from the training data\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "\n",
        "# Checking the shape of the resulting vector representation of the training data\n",
        "vectors.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqmXUl5MlWV",
        "outputId": "d0fa5037-d080-4939-f13e-0daa51c17264"
      },
      "id": "fqqmXUl5MlWV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0f74b3",
      "metadata": {
        "id": "4d0f74b3"
      },
      "source": [
        "# 3) First Iteration of the model\n",
        "#### (train based on data including headers/footers/quotes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c504979",
      "metadata": {
        "id": "2c504979"
      },
      "source": [
        "### Multinomial NB Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming test data into document-term matrix\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "\n",
        "# Initializing the Multinomial Naive Bayes classifier object with alpha=0.01\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "\n",
        "# Fitting the classifier on the training data\n",
        "clf.fit(vectors, newsgroups_train.new_target)\n",
        "\n",
        "# Making predictions on the test data\n",
        "pred = clf.predict(vectors_test)\n",
        "\n",
        "# Calculating the Weighted Average F1-Score\n",
        "score1 = metrics.f1_score(newsgroups_test.new_target, pred, average='weighted')\n",
        "\n",
        "# Calculating the Macro Average F1-Score\n",
        "score2 = metrics.f1_score(newsgroups_test.new_target, pred, average='macro')\n",
        "\n",
        "# Printing the results\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BfBKihLNGgS",
        "outputId": "64641544-ebc6-429d-e11b-07a745dda896"
      },
      "id": "4BfBKihLNGgS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.9057288478213792\n",
            "Macro Average F1-Score: 0.8778762480896006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ed4d1f",
      "metadata": {
        "id": "47ed4d1f"
      },
      "source": [
        "#### a) Look at top ten feature/words after model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c17fb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9c17fb3",
        "outputId": "cf3d85a1-18c1-4158-d929-310fa745275f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Religion: it you god in and is that to of the\n",
            "Technology: that for in edu it is and of to the\n",
            "Other: shipping offer of 00 to and edu the for sale\n",
            "Recreation: you is that it edu of and in to the\n",
            "Science: be edu it that in is and of to the\n",
            "Politics: edu it is you that in and to of the\n"
          ]
        }
      ],
      "source": [
        "def show_top10(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
        "\n",
        "show_top10(clf, vectorizer, newsgroups_train.new_target_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac549a1",
      "metadata": {
        "id": "dac549a1"
      },
      "source": [
        "#### b) Test out with 4 made-up text strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb48d21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeb48d21",
        "outputId": "30ccfd01-5409-4d13-9ee9-d83271b32d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Technology\n",
            "'Vote Jimmy for president' => Politics\n",
            "'I need a trip' => Recreation\n"
          ]
        }
      ],
      "source": [
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99da75f5",
      "metadata": {
        "id": "99da75f5"
      },
      "source": [
        "### SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a Support Vector Machine Classifier with a linear kernel, C=1 and a random seed of 42\n",
        "clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Fitting the model to the training data and target labels\n",
        "clf.fit(vectors, newsgroups_train.new_target)\n",
        "\n",
        "# Predicting the target labels for the test data\n",
        "pred = clf.predict(vectors_test)\n",
        "\n",
        "# Calculating the weighted average F1-Score for the predictions\n",
        "score1 = metrics.f1_score(newsgroups_test.new_target, pred, average='weighted')\n",
        "\n",
        "# Calculating the macro average F1-Score for the predictions\n",
        "score2 = metrics.f1_score(newsgroups_test.new_target, pred, average='macro')\n",
        "\n",
        "# Printing the weighted average F1-Score and the macro average F1-Score\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drii3heJODNj",
        "outputId": "1440473b-82a0-4785-b7ca-179094f6c988"
      },
      "id": "Drii3heJODNj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.910525601732771\n",
            "Macro Average F1-Score: 0.8989236822491088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e3d208",
      "metadata": {
        "id": "11e3d208"
      },
      "outputs": [],
      "source": [
        "#Exploring the classification output of the first ten features\n",
        "def show_top10(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
        "\n",
        "show_top10(clf, vectorizer, newsgroups_train.new_target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f089f697",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f089f697",
        "outputId": "d613ad71-2ab7-4eaf-ab18-ababad531541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Technology\n",
            "'Vote Jimmy for president' => Technology\n",
            "'I need a trip' => Technology\n"
          ]
        }
      ],
      "source": [
        "#Testing the model with completely new external data\n",
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe4f87e",
      "metadata": {
        "id": "8fe4f87e"
      },
      "source": [
        "# 4) Second Iteration of the model\n",
        "#### (train based on data including headers/footers/quotes, dropping common words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4df13fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4df13fb",
        "outputId": "cc4ec521-0bbe-44d2-f637-4810cbe8090c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 129796)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84512fb5",
      "metadata": {
        "id": "84512fb5"
      },
      "source": [
        "### Multinomial NB Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a917751c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a917751c",
        "outputId": "2d2c19c2-74e3-46e0-f957-b4e4eb2e3d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.9061555127259279\n",
            "Macro Average F1-Score: 0.8770841773714819\n"
          ]
        }
      ],
      "source": [
        "#Training, testing ane evaluation of the model\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(vectors, newsgroups_train.new_target)\n",
        "pred = clf.predict(vectors_test)\n",
        "score1 = metrics.f1_score(newsgroups_test.new_target, pred, average='weighted')\n",
        "score2 = metrics.f1_score(newsgroups_test.new_target, pred, average='macro')\n",
        "\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506c00bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "506c00bc",
        "outputId": "acd8c0ae-6e98-4ad5-f721-87019f6bbea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Religion: church com christians christian bible keith people jesus edu god\n",
            "Technology: host use thanks university organization subject lines com windows edu\n",
            "Other: lines condition distribution university new shipping offer 00 edu sale\n",
            "Recreation: subject organization game writes team article car ca com edu\n",
            "Science: article writes nasa chip encryption clipper space key com edu\n",
            "Politics: israeli government don article gun writes israel people com edu\n"
          ]
        }
      ],
      "source": [
        "#Exploring the classification of the first ten documents\n",
        "def show_top10(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
        "\n",
        "show_top10(clf, vectorizer, newsgroups_train.new_target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce94cdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dce94cdc",
        "outputId": "460ae06a-03c2-4a1b-ccf5-7b3b2f739675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Technology\n",
            "'Vote Jimmy for president' => Politics\n",
            "'I need a trip' => Recreation\n"
          ]
        }
      ],
      "source": [
        "#Testing our model using external data\n",
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bb987d",
      "metadata": {
        "id": "26bb987d"
      },
      "source": [
        "### SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13627694",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13627694",
        "outputId": "58a2ed59-8e9d-422b-a838-befd37cb8f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.912611928711664\n",
            "Macro Average F1-Score: 0.8992232049992123\n"
          ]
        }
      ],
      "source": [
        "#Training, testing and evaluating the SVM model\n",
        "clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "clf.fit(vectors, newsgroups_train.new_target)\n",
        "pred = clf.predict(vectors_test)\n",
        "score1 = metrics.f1_score(newsgroups_test.new_target, pred, average='weighted')\n",
        "score2 = metrics.f1_score(newsgroups_test.new_target, pred, average='macro')\n",
        "\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e61701f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e61701f",
        "outputId": "393fc486-6ac7-4295-a544-4549283cddb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Technology\n",
            "'Vote Jimmy for president' => Politics\n",
            "'I need a trip' => Technology\n"
          ]
        }
      ],
      "source": [
        "#Testing our model using completely new extrenal data\n",
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eccbeca5",
      "metadata": {
        "id": "eccbeca5"
      },
      "source": [
        "# 5) Third Iteration of the model\n",
        "#### (train based on data excluding headers/titles/subjects, dropping common words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training set of the 20 newsgroups dataset, with headers, footers and quotes removed\n",
        "newsgroups_train_2 = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Load the testing set of the 20 newsgroups dataset, with headers, footers and quotes removed\n",
        "newsgroups_test_2 = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n"
      ],
      "metadata": {
        "id": "8ieHeQNKP7oL"
      },
      "id": "8ieHeQNKP7oL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target names for the new categories\n",
        "target_names_new = [\"Religion\", \"Technology\", \"Other\", \"Recreation\", \"Science\", \"Politics\"]\n",
        "\n",
        "# Create a mapping from the old target categories to the new ones\n",
        "old_to_new_target = ({0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1,\n",
        "                      6: 2, 7: 3, 8: 3, 9: 3, 10: 3, 11: 4, \n",
        "                      12: 1, 13: 4, 14: 4, 15: 0, 16: 5, 17: 5, 18: 5, 19: 5})\n",
        "\n",
        "# Add the new target column to the training dataset\n",
        "newsgroups_train_2[\"new_target\"] = np.array([old_to_new_target[x] for x in newsgroups_train_2.target])\n",
        "\n",
        "# Add the new target names column to the training dataset\n",
        "newsgroups_train_2[\"new_target_names\"] = np.array(target_names_new)\n",
        "\n",
        "# Add the new target column to the testing dataset\n",
        "newsgroups_test_2[\"new_target\"] = np.array([old_to_new_target[x] for x in newsgroups_test_2.target])\n",
        "\n",
        "# Add the new target names column to the testing dataset\n",
        "newsgroups_test_2[\"new_target_names\"] = np.array(target_names_new)\n"
      ],
      "metadata": {
        "id": "8ql1yAA1Qo4Y"
      },
      "id": "8ql1yAA1Qo4Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e142e2f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e142e2f5",
        "outputId": "78673c88-d7cf-45d3-beb0-7d877d78d67c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 101322)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#vectorize the data\n",
        "vectors_2 = vectorizer.fit_transform(newsgroups_train_2.data)\n",
        "vectors_2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2906ab22",
      "metadata": {
        "id": "2906ab22"
      },
      "source": [
        "## Multinomial NB model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ae545b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99ae545b",
        "outputId": "092c5f6d-8969-47e8-f20f-5df25e1a9119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.8163039273316107\n",
            "Macro Average F1-Score: 0.7825500811273862\n"
          ]
        }
      ],
      "source": [
        "#Training, texting and evaluation our model\n",
        "vectors_test_2 = vectorizer.transform(newsgroups_test_2.data)\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(vectors_2, newsgroups_train_2.new_target)\n",
        "pred = clf.predict(vectors_test_2)\n",
        "score1 = metrics.f1_score(newsgroups_test_2.new_target, pred, average='weighted')\n",
        "score2 = metrics.f1_score(newsgroups_test_2.new_target, pred, average='macro')\n",
        "\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a567fd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a567fd9",
        "outputId": "e26a94a0-1ce0-46b7-9873-b662c250be01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Religion: just say believe church don think bible people jesus god\n",
            "Technology: file drive problem card like does know use thanks windows\n",
            "Other: asking email sell price condition new shipping offer 00 sale\n",
            "Recreation: good think don bike like just year team game car\n",
            "Science: chip know like just don clipper people encryption space key\n",
            "Politics: like know did think gun government just israel don people\n"
          ]
        }
      ],
      "source": [
        "#Exploring the classification output of the first ten documnents\n",
        "def show_top10(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
        "\n",
        "show_top10(clf, vectorizer, newsgroups_train_2.new_target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0c4490",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e0c4490",
        "outputId": "f56f0aa0-aaca-4d90-8629-2279c1ecad8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Science\n",
            "'Vote Jimmy for president' => Recreation\n",
            "'I need a trip' => Recreation\n"
          ]
        }
      ],
      "source": [
        "#Testing our model with new external data\n",
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c42b99",
      "metadata": {
        "id": "43c42b99"
      },
      "source": [
        "## SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20498f9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20498f9b",
        "outputId": "9c10f111-7ced-4d04-d3b3-dedb7621cafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Average F1-Score: 0.795195286101736\n",
            "Macro Average F1-Score: 0.7745307883443774\n"
          ]
        }
      ],
      "source": [
        "# clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
        "clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "clf.fit(vectors_2, newsgroups_train_2.new_target)\n",
        "pred = clf.predict(vectors_test_2)\n",
        "score1 = metrics.f1_score(newsgroups_test_2.new_target, pred, average='weighted')\n",
        "score2 = metrics.f1_score(newsgroups_test_2.new_target, pred, average='macro')\n",
        "\n",
        "print(\"Weighted Average F1-Score:\", score1)\n",
        "print(\"Macro Average F1-Score:\", score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c38e8d",
      "metadata": {
        "id": "89c38e8d"
      },
      "outputs": [],
      "source": [
        "#Exploring the classification of the top 10 documents\n",
        "def show_top10(classifier, vectorizer, categories):\n",
        "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
        "    for i, category in enumerate(categories):\n",
        "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
        "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
        "\n",
        "show_top10(clf, vectorizer, newsgroups_train_2.new_target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "706e3e67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "706e3e67",
        "outputId": "76487750-54c6-433e-979c-4d21b53497c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => Religion\n",
            "'ChatGPT is useful for assignments' => Science\n",
            "'Vote Jimmy for president' => Recreation\n",
            "'I need a trip' => Politics\n"
          ]
        }
      ],
      "source": [
        "#Testing our model using new external data\n",
        "docs_new = ['God is love', 'ChatGPT is useful for assignments', 'Vote Jimmy for president', 'I need a trip']\n",
        "X_new_counts = vectorizer.transform(docs_new)\n",
        "\n",
        "predicted = clf.predict(X_new_counts)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "     print('%r => %s' % (doc, newsgroups_train.new_target_names[category]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502e44f4",
      "metadata": {
        "id": "502e44f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}